---
layout: post
title:  "Remote Procedure Call"
date:   2016-04-12 09:00:00 -0000
categories: pl
group: pl
---

_This is one post in a series about programming models and languages for distributed computing that I'm writing as part of my [history of distributed programming techniques](https://github.com/cmeiklejohn/PMLDC)._


<h2 id="relevant-reading">Relevant Reading</h2>
<ul>
<li><p><em>A Note On Distributed Computing</em>, Kendall, Waldo, Wollrath, Wyant, 1994 <span class="citation">Kendall et al. (1994)</span>.</p></li>
<li><p><em>It’s Just A Mapping Problem</em>, Vinoski, 2003 <span class="citation">Vinoski (2003)</span>.</p></li>
<li><p><em>Convenience Over Correctness</em>, Vinoski, 2008 <span class="citation">Vinoski (2008)</span>.</p></li>
</ul>
<h2 id="commentary">Commentary</h2>
<blockquote>
<p>“Does developer convenience really trump correctness, scalability, performance, separation of concerns, extensibility, and accidental complexity?” <span class="citation">Vinoski (2008)</span></p>
</blockquote>
<h3 id="timeline">Timeline</h3>
<ul>
<li><p><span>1974:</span> RFC 674,<br />
“Procedure Call Protocol Documents, Version 2”</p></li>
<li><p><span>1975:</span> RFC 684,<br />
“A Commentary on Procedure Calling as a Network Protocol”</p></li>
<li><p><span>1976:</span> RFC 707,<br />
“A High-Level Framework for Network-Based Resource Sharing”</p></li>
<li><p><span>1984:</span> “Implementing Remote Procedure Calls”</p></li>
<li><p><span>1987:</span> Distribution and Abstract Types in Emerald</p></li>
<li><p><span>1988:</span> Distributed Programing in Argus</p></li>
<li><p><span>1988:</span> RFC 1057,<br />
“Remote Procedure Call Protocol Specification, Version 2”</p></li>
<li><p><span>1991:</span> CORBA 1.0</p></li>
<li><p><span>1996:</span> “A Distributed Object Model for the Java System”</p></li>
<li><p><span>1997:</span> CORBA 2.0</p></li>
<li><p><span>1999+:</span> EJB, XML-RPC, SOAP, REST</p></li>
</ul>
<h3 id="overview">Overview</h3>
<p>Remote Procedure Call (RPC) is a general term for executing a subroutine in a different address space without writing the actual code used to perform the remote execution. To provide an example, we can imagine a user wishing to invoke the random number generator function on another machine, but, the only difference between the local and remote invocation is supplying an additional node identifier where it should occur. While not the first implementation, because it was preceded by Apollo Computer’s Network Computing System (NCS), the first major implementation to be widely known and adopted was the SunRPC mechanism, from Sun Microsystems, used to back their Network File System (NFS).</p>
<p>Remote Procedure Call mechanisms you may be more familiar with are Java’s Remote Method Invocation (RMI), it’s predecessor Modula-3’s Network Objects, XML-RPC, SOAP, CORBA, Avro, Facebook’s, (now Apache) Thrift, Google’s Protocol Buffers, and Twitter’s Finagle.</p>
<h3 id="rfc-684">RFC 684</h3>
<blockquote>
<p>“Rather, we take exception to PCP’s underlying premise: that the procedure calling discipline is the starting point for building multi-computer systems.”</p>
</blockquote>
<p>RFC 684 is commentary on RFC 674 that introduced the Procedure Call Paradigm, Version 2 (PCP). This commentary highlights, what boils down to, three major points from a critical analysis of the Procedure Call Paradigm.</p>
<ul>
<li><p>Procedure calling is usually a primitive operation; by primitive, it should be an extremely fast context switch operation performed by the underlying abstraction.</p></li>
<li><p>Local and remote calls each have different cost profiles; remote calls can be delayed, and in the event of failure, may <strong>never return</strong>.</p></li>
<li><p>Asynchronous message passing, or sending a message and waiting for a response when the response is needed, is a much better model because it makes the passing of messages <strong>explicit</strong>.</p></li>
</ul>
<p>Following from these three points, we see a series of concerns develop about this programming paradigm, all of which become a common theme across the 40+ years in RPC’s history. These are:</p>
<ul>
<li><p>Difficulty in recovery after malfunction or error. For instance, do we rollback or throw exceptions? How do we handle these errors? Can we just try again?</p></li>
<li><p>Difficulty in sequencing operations. If all calls are synchronous and some of these calls can fail, it can require a significant amount of code to ensure correct re-execution to preserve order moving forward.</p></li>
<li><p>Remote Procedure Call forces <strong>synchronous programming</strong>: a method is invoked and the invoking process waits for a response.</p></li>
<li><p>Backpressure, or blocking on previous actions completing, load-shedding, or dropping messages on the floor when the system is overloaded, and priority servicing become more difficult with the call-and-response model of Remote Procedure Call.</p></li>
</ul>
<h3 id="rfc-707">RFC 707</h3>
<blockquote>
<p>“Because of this cost differential, the applications programmer must exercise discretion in his use of remote resources, even though the mechanics of their use will have been greatly simplified by the RTE. Like virtual memory, the procedure call model offers great convenience, and therefore power, in exchange for reasonable alertness to the possibilities of abuse.”</p>
</blockquote>
<p>RFC 707 generalizes the ideas from RFC 684 and discusses the problem of resources sharing for services such as TELNET and FTP: each of these services presents a <em>different</em> interface for interacting with it, which requires the operator to know the specific protocol for interacting with that service. In realizing that both services like TELNET and FTP follow the call-and-response model, the authors propose an alternative idea: rather than needing to know all of the available commands and protocols on the remote machine, can we define a generic interface for executing a remote procedure that takes an argument list and follows the call-and-response model?</p>
<p>While we can, the problems of control flow and priority servicing outlined in RFC 684 remain; however, not enough that it prevents this model from being adopted by many systems in the future.</p>
<h3 id="corba">CORBA</h3>
<p>The Common Object Request Broker Architecture (CORBA) is an abstraction for object-oriented languages, popularized by C++, that allows you to communicate between different languages and different address spaces running on different machines. CORBA relied on the use of an Interface Definition Language (IDL) for specifying the interfaces of remote classes of objects; this IDL was used to generate stubs of what the remote systems object interfaces appeared as on the local machine. These IDL’s would be used to generate mappings between the abstract interfaces provided by the IDL’s and the actual implementations in languages such as C++ and Java.</p>
<p>CORBA attempted to provide several benefits to the application developer: language independence, OS-independence, architecture-independence, static typing through a mapping of abstract types in the IDL to machine and language specific implementations of those types, and object transfer, where objects can be migrated over the wire between different machines. CORBA’s promise was that through the use of mapping that remote calls could appear as local calls, and that distributed systems related exceptions could be mapped into local exceptions and handled by local exception handling mechanisms.</p>
<p>However, as Vinoski points out in 2003, the evaluation of programming languages and abstractions based on transparency alone is flawed:</p>
<blockquote>
<p>“The goal is to merge middleware abstractions directly into the realm of the programming language, minimizing the impedance mismatch between the programming language world and the middleware world. For example, mappings make request invocations on distributed objects and services appear as normal programming-language function calls, and they map distributed system exceptions into native programming language exception-handling mechanisms.” <span class="citation">Vinoski (2003)</span></p>
</blockquote>
<h3 id="a-note-on-distributed-computing">“A Note On Distributed Computing”</h3>
<blockquote>
<p>“It is the thesis of this note that this unified view of objects is mistaken.” <span class="citation">Kendall et al. (1994)</span></p>
</blockquote>
<p>In this pinnacle Waldo paper, they argue that “it is perilous to ignore the differences” between local and distributed computing and that the unified view of objects is flawed. <span class="citation">Kendall et al. (1994)</span> They cite two independent groups of work, the systems of Emerald and Argus, and the modern equivalents of those systems, Microsoft’s DCOM and OMG’s CORBA: all systems that extended the RPC mechanism to objects and method invocation.</p>
<p>We can summarize the “promise” of the unified view of objects, as Waldo does in the paper.</p>
<ul>
<li><p>Applications are designed using interfaces on the local machine.</p></li>
<li><p>Objects are relocated, because of the transparency of location, to gain the desired application performance.</p></li>
<li><p>The application is then tested with “real bullets.”</p></li>
</ul>
<p>This strategy for the design of a distributed application has two fundamental flaws. First, that the design of an application can be done with interfaces alone, and that this design will be discovered during the development of the application. Second, that application correctness does not depend on object location, but only the interfaces to each object.</p>
<p>Waldo swats down this design with the “three false principles” <span class="citation">Kendall et al. (1994)</span>:</p>
<blockquote>
<p>“there is a single natural object-oriented design for a given application, regardless of the context in which that application will be deployed”</p>
</blockquote>
<blockquote>
<p>“failure and performance issues are tied to the implementation of the components of an application, and consideration of these issues should be left out of an initial design”</p>
</blockquote>
<blockquote>
<p>“‘the interface of an object is independent of the context in which that object is used’’</p>
</blockquote>
<h3 id="every-10-years...">“Every 10 years...”</h3>
<blockquote>
<p>“The hard problems in distributed computing are not the problems of getting things on and off the wire.” <span class="citation">Kendall et al. (1994)</span></p>
</blockquote>
<p>Waldo argues that every ten years we approach the problem of attempting to unify the view of local and remote computing and run into the same problems, again and again: <strong>local and remote computing are fundamentally different.</strong></p>
<h4 id="latency">Latency</h4>
<p>Waldo argues that the most obvious difference should be the issues of latency: if you ignore latency, you will end up directly impacting software performance. He states that is it wrong to “rely on steadily increasing speed of the underlying hardware” and that it is not always possible to test with “real bullets”. Performance analysis and relocation is non-trivial and a design that is optimal at one point will not necessarily stay optimal.</p>
<h4 id="memory-access">Memory Access</h4>
<p>His criticisms of memory access are very specific to CORBA and its predecessors in the object space: objects can retain pointers to objects in the same address space, but once moved these pointers will no longer be valid. He states that one approach to solving the problem is distributed shared memory, but more practically techniques such as marshalling or replacement by CORBA references, which are marshalled for distributed access, are used.</p>
<h4 id="partial-failure">Partial Failure</h4>
<p>Finally, the most fundamental problem: partial failure. In local computing, he argues, failures are detectable, total, and result in a return of control. This is not true with distributed computing: independent components may fail, failures are partial and a failure of a link is indistinguishable from a failure of a remote processor.</p>
<p>As always, Waldo says it best:</p>
<blockquote>
<p>“The question is not ‘can you make remote method invocation look like local method invocation?’ but rather ‘what is the price of making remote method invocation identical to local method invocation?’” <span class="citation">Kendall et al. (1994)</span></p>
</blockquote>
<p>Waldo argues that there is only two paths forward if we want to achieve the goal of the unified object model.</p>
<ul>
<li><p>Treat all objects as local.</p></li>
<li><p>Treat all objects as remote.</p></li>
</ul>
<p>However, he states that if the real goal is to “make distributed computing as simple as local computing”, that the only real path forward is the first. This approach, he believes, is flawed, and that distribution is fundamentally different, and must be treated so.</p>
<blockquote>
<p>“This approach would also defeat the overall purpose of unifying the object models. The real reason for attempting such a unification is to make distributed computing more like local computing and thus make distributed computing easier. This second approach to unifying the models makes local computing as complex as distributed computing.” <span class="citation">Kendall et al. (1994)</span></p>
</blockquote>
<p>The paper provides two examples of where this paradigm is problematic, but we will highlight one case, that builds upon RPC.</p>
<h3 id="network-file-system">Network File System</h3>
<p>Sun Microsystem’s <strong>Network File System (NFS)</strong>, built upon RPC, is one of the first distributed file systems to gain popularity. Network File System adhered to the existing filesystem API, but introduced an entire new class of failures resulting from network partitions, partial failure, and high latency. Network File System is a stateless protocol implemented in UDP; the decision to implement it this way is motivated by the perceived ease in debugging protocols that do not carry state.</p>
<p>Network File System operated in two modes: soft mounting and hard mounting. Soft mounting introduced a series of new error codes related to the additional ways file operations could fail: these error codes were not known by existing UNIX applications and led to smaller adoption of this approach. Hard mounting introduced the opposite behavior for failures related to the network: <strong>operations would block until they could be completed successfully</strong>.</p>
<p><em>It’s just a mapping problem, right?</em> <span class="citation">Vinoski (2003)</span></p>
<h3 id="convenience-over-correctness">“Convenience Over Correctness”</h3>
<blockquote>
<p>“We have a general-purpose imperative programming-language hammer, so we treat distributed computing as just another nail to bend to fit the programming models.” <span class="citation">Vinoski (2008)</span></p>
</blockquote>
<p>Vinoski highlights three very important points in “Convenience Over Correctness” criticism of RPC many years later.</p>
<ul>
<li><p><strong>Interface Definition Languages (IDL) “impedance mismatch”</strong>: base types may be easy to map, but more complex types may be less so.</p></li>
<li><p><strong>Scalability:</strong> the RPC paradigm does not have any first class support for caching, or mechanisms for mitigating high latency, and is remains a rather primitive operation to build distributed applications with.</p></li>
<li><p><strong>Representational State Transfer (REST)</strong>: REST is good: it specifically addresses the problem of managing distributed resources; but most frameworks built on top of REST alter the abstraction and present something that repeats the problem <a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>.</p></li>
</ul>
<h2 id="impact-and-implementations">Impact and Implementations</h2>
<p>Remote Procedure Call (RPC) has been around for a very long time and while many opponents of RPC have been extremely critical of it, it still remains one of the most widely used way of writing distributed applications. There’s an unprecedented amount of use of frameworks for RPC like Twitter’s Finagle, Google’s Protocol Buffers, and Apache’s Thrift deployed and used in production applications every day.</p>
<p>Newer frameworks, such as Google’s gRPC for HTTP/2.0 continue to reduce the amount of complexity in building applications with them, attempting to bring RPC to an even wider audience. These frameworks claim that since they do not attempt to hide that the calls are remote, that it is a better abstraction. However, now we have returned to the aforementioned problem of soft mounting in NFS: explicitly handling the flow control from the array of possible network exceptions that could occur.</p>
<p>But, the question we have to ask ourselves is whether the abstraction of an individual method invocation or function call is the correct paradigm for building distributed applications. Is the idea of treating all remote objects as local, and making distribution as transparent as possible, the correct decision moving forward? Does it mask failure modes that will allow developers to build applications that will not operate correctly under partial failure?</p>
<p>When we talk about distributed programming languages today, many developers equate this to <strong>programming languages</strong> that can be, and have been used, to build <strong>distributed systems.</strong> For example, any language with concurrency primitives and the ability to open a network socket would suffice to build these systems; this does not imply that these languages are distributed programming languages.</p>
<p>But, a <strong>distributed programming language</strong> is where the distribution is <strong>first class</strong>. Languages like Go are more closely related to <strong>concurrent</strong> languages, where concurrency is first class; and, while concurrency is a requirement for distribution, these are different topics. CORBA is an example of trying to make distribution first class in languages such as C++.</p>
<p>Erlang <span class="citation">Claessen and Svensson (2005; Svensson and Fredlund 2007a; Svensson and Fredlund 2007b)</span> is one language where distribution is first class. Erlang has a RPC mechanism, but prefers the use of asynchronous message passing between processes. In fact, the RPC mechanism in Erlang is implemented using Erlang’s native asynchronous message passing. While you can peek under the covers and see <strong>where</strong> processes are running, Erlang tries to make the programmer assume that each process could be executing on a different node. Motivated by the expressiveness of the design, both Distributed Process, from the Cloud Haskell group, and Akka, in Scala, are examples that attempt to bring Erlang-style semantics to Haskell and Scala, respectively.</p>
<p>One approach taken in the Scala community for distributed programming is serializable closures <span class="citation">Miller, Haller, and Odersky (2014)</span>, or what’s known as the function shipping paradigm. In this model, entire functions are moved across the network, where the type system is used to ensure that all of values in scope can be properly serialized or marshalled as these closures move across the network. While this solves some of the problematic points in systems like CORBA and DCOM, it does not have a solution for the problem of how to ensure exacty-once execution of functions, or to handle partial failure where you can not distinguish the failure of the remote node from the network.</p>
<p>Languages like Bloom, and Bloom<sub>L</sub>, and Lasp <span class="citation">Alvaro et al. (2011; Conway et al. 2012; Meiklejohn and Van Roy 2015)</span> take an alternative approach: can we build abstractions that rely on asynchronous programming, very weak ordering and structuring our applications in such a way where they are tolerant to network anomalies such as message duplication and message re-ordering. While this approach is more expensive in terms of state transmission, and more restrictive in what types of computations can be expressed, this style of programming supports the creation of <em>correct-by-construction</em> distributed applications. These applications are highly tolerant to anomalies resulting from network failures by assuming all actors in the system are distributed. The restrictions, however, might prohibit wide adoption of these techniques.</p>
<p>So, we ask again:</p>
<blockquote>
<p>“Does developer convenience really trump correctness, scalability, performance, separation of concerns, extensibility, and accidental complexity?” <span class="citation">Vinoski (2008)</span></p>
</blockquote>
<div id="refs" class="references">
<div id="ref-alvaro2011consistency">
<p>Alvaro, Peter, Neil Conway, Joseph M Hellerstein, and William R Marczak. 2011. “Consistency Analysis in Bloom: A CALM and Collected Approach.” In <em>CIDR</em>, 249–60. Citeseer.</p>
</div>
<div id="ref-claessen2005semantics">
<p>Claessen, Koen, and Hans Svensson. 2005. “A Semantics for Distributed Erlang.” In <em>Proceedings of the 2005 ACM SIGPLAN Workshop on Erlang</em>, 78–87. ACM.</p>
</div>
<div id="ref-conway2012logic">
<p>Conway, Neil, William R Marczak, Peter Alvaro, Joseph M Hellerstein, and David Maier. 2012. “Logic and Lattices for Distributed Programming.” In <em>Proceedings of the Third ACM Symposium on Cloud Computing</em>, 1. ACM.</p>
</div>
<div id="ref-kendall1994note">
<p>Kendall, Samuel C, Jim Waldo, Ann Wollrath, and Geoff Wyant. 1994. “A Note on Distributed Computing.” Sun Microsystems, Inc.</p>
</div>
<div id="ref-meiklejohn2015lasp">
<p>Meiklejohn, Christopher, and Peter Van Roy. 2015. “Lasp: A Language for Distributed, Eventually Consistent Computations with CRDTs.” In <em>Proceedings of the First Workshop on Principles and Practice of Consistency for Distributed Data</em>, 7. ACM.</p>
</div>
<div id="ref-miller2014spores">
<p>Miller, Heather, Philipp Haller, and Martin Odersky. 2014. “Spores: A Type-Based Foundation for Closures in the Age of Concurrency and Distribution.” In <em>ECOOP 2014–Object-Oriented Programming</em>, 308–33. Springer.</p>
</div>
<div id="ref-svensson2007more">
<p>Svensson, Hans, and Lars-Ake Fredlund. 2007a. “A More Accurate Semantics for Distributed Erlang.” In <em>Erlang Workshop</em>, 43–54. Citeseer.</p>
</div>
<div id="ref-svensson2007programming">
<p>Svensson, Hans, and Lars-Åke Fredlund. 2007b. “Programming Distributed Erlang Applications: Pitfalls and Recipes.” In <em>Proceedings of the 2007 SIGPLAN Workshop on ERLANG Workshop</em>, 37–42. ACM.</p>
</div>
<div id="ref-vinoski2003s">
<p>Vinoski, Steve. 2003. “It’s Just a Mapping Problem [Computer Application Adaptation].” <em>Internet Computing, IEEE</em> 7 (3). IEEE: 88–90.</p>
</div>
<div id="ref-vinoski2008convenience">
<p>———. 2008. “Convenience over Correctness.” <em>Internet Computing, IEEE</em> 12 (4). IEEE: 89–92.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>For instance, if one was to build an object model on top of REST.<a href="#fnref1">↩</a></p></li>
</ol>
</div>
